# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import sys                          # ì‹œìŠ¤í…œ ê²½ë¡œë¥¼ ë‹¤ë£¨ê¸° ìœ„í•¨
import os                           # ìš´ì˜ì²´ì œì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•¨ (íŒŒì¼ ê²½ë¡œ, í´ë” ìƒì„± ë“±)
import subprocess                   # ì™¸ë¶€ í”„ë¡œì„¸ìŠ¤(yt-dlp)ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•¨
import cv2                          # OpenCV, ë™ì˜ìƒê³¼ ì´ë¯¸ì§€ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•¨
import glob                         # íŠ¹ì • íŒ¨í„´ì˜ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•¨
import torch                        # PyTorch, ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê¸°ë³¸ í”„ë ˆì„ì›Œí¬
import numpy as np                  # ìˆ˜ì¹˜ ê³„ì‚°, íŠ¹íˆ ì´ë¯¸ì§€ ë°°ì—´ì„ ë‹¤ë£¨ê¸° ìœ„í•¨
from youtubesearchpython import VideosSearch  # ìœ íŠœë¸Œ ê²€ìƒ‰ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from PIL import Image               # ì´ë¯¸ì§€ ì²˜ë¦¬(íŠ¹íˆ í˜•ì‹ ë³€í™˜)ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import torchvision.transforms as T  # ì´ë¯¸ì§€ ë³€í™˜(ë¦¬ì‚¬ì´ì¦ˆ, ì •ê·œí™” ë“±)ì„ ìœ„í•œ PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬

# GroundingDINO ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì¶”ê°€ ë° í•¨ìˆ˜ ì„í¬íŠ¸
sys.path.append("C:/HDLC/GroundingDINO") # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ ë° ê²½ë¡œ ìˆ˜ì •
from groundingdino.util.inference import load_model, predict

# --- ì„¤ì • (Configuration) ---
# GroundingDINO ëª¨ë¸ì˜ ì„¤ì • íŒŒì¼ê³¼ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
CONFIG_PATH = "C:/HDLC/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py"
WEIGHTS_PATH = "C:/HDLC/GroundingDINO/weights/groundingdino_swint_ogc.pth"

# ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ
print("GroundingDINO ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
model = load_model(CONFIG_PATH, WEIGHTS_PATH)
print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")


# 1. ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ í•¨ìˆ˜
def search_youtube_videos(keywords, limit=5):
    """ì§€ì •ëœ í‚¤ì›Œë“œë¡œ ìœ íŠœë¸Œë¥¼ ê²€ìƒ‰í•˜ê³  ë™ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    video_infos = []
    print(f"\n'{', '.join(keywords)}' í‚¤ì›Œë“œë¡œ ìœ íŠœë¸Œ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    for keyword in keywords:
        # í‚¤ì›Œë“œë¡œ ë™ì˜ìƒ ê²€ìƒ‰ ì‹¤í–‰
        search = VideosSearch(keyword, limit=limit)
        results = search.result()['result']
        print(f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ì˜ìƒ ë°œê²¬.")
        for result in results:
            if result['type'] != 'video': continue # ë™ì˜ìƒ íƒ€ì…ì´ ì•„ë‹ˆë©´ ê±´ë„ˆëœ€
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë™ì˜ìƒ IDë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œì¤€ URLì„ ìƒì„± (ì•ˆì •ì„± í™•ë³´)
            video_infos.append({
                "keyword": keyword,
                "title": result['title'],
                "url": f"https://www.youtube.com/watch?v={result['id']}"
            })
    return video_infos


# 2. GroundingDINO ì˜ˆì¸¡ ìˆ˜í–‰ í•¨ìˆ˜
def run_groundingdino_predict(model, image_np, caption, box_threshold=0.3, text_threshold=0.25):
    """ì…ë ¥ëœ ì´ë¯¸ì§€(NumPy ë°°ì—´)ì—ì„œ í…ìŠ¤íŠ¸(caption)ì— í•´ë‹¹í•˜ëŠ” ê°ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤."""
    # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ê¸° ìœ„í•œ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì •ì˜
    transform = T.Compose([
        T.ToPILImage(),                             # NumPy ë°°ì—´ì„ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        T.Resize((800, 800)),                       # ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
        T.ToTensor(),                               # ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
        T.Normalize([0.48145466, 0.4578275, 0.40821073], # ì´ë¯¸ì§€ ì •ê·œí™”
                    [0.26862954, 0.26130258, 0.27577711])
    ])

    # OpenCVë¡œ ì½ì€ NumPy ë°°ì—´(BGR)ì„ PyTorch í…ì„œ(RGB)ë¡œ ë³€í™˜
    image_tensor = transform(image_np)

    # ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¡œë¶€í„° í˜„ì¬ ì¥ì¹˜(CPU ë˜ëŠ” GPU)ë¥¼ ìë™ìœ¼ë¡œ ì•Œì•„ëƒ„
    device = next(model.parameters()).device
    
    # ëª¨ë¸ì˜ predict í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê°ì²´ íƒì§€ ìˆ˜í–‰
    boxes, logits, phrases = predict(
        model=model,
        image=image_tensor,         # ë³€í™˜ëœ ì´ë¯¸ì§€ í…ì„œë¥¼ ì „ë‹¬
        caption=caption,            # ì°¾ê³ ì í•˜ëŠ” ê°ì²´ì˜ ì´ë¦„ (ì˜ˆ: "car")
        box_threshold=box_threshold, # ê°ì²´ íƒì§€ ê²½ê³„ê°’
        text_threshold=text_threshold, # í…ìŠ¤íŠ¸ ë§¤ì¹­ ê²½ê³„ê°’
        device=device               # ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” ì¥ì¹˜ë¥¼ ëª…ì‹œ
    )
    return boxes, phrases


# 3. AI ê¸°ë°˜ ì˜ìƒ ìœ íš¨ì„± ê²€ì¦ í•¨ìˆ˜
def is_valid_video(url, model, target_class="car"):
    """yt-dlpë¡œ ì˜ìƒì˜ ì¼ë¶€ë§Œ ë°›ì•„ GroundingDINOë¡œ ì›í•˜ëŠ” ê°ì²´ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    temp_path = "temp_check.mp4" # ê²€ì¦ìš© ì„ì‹œ ë™ì˜ìƒ íŒŒì¼ ì´ë¦„
    try:
        print(f"   [yt-dlp] ì˜ìƒ ê²€ì¦ ì‹œì‘: {url}")
        # yt-dlpë¥¼ ì‚¬ìš©í•´ ì˜ìƒì˜ ì•ë¶€ë¶„ 10ì´ˆë§Œ ë¹ ë¥´ê²Œ ë‹¤ìš´ë¡œë“œ
        subprocess.run([
            "yt-dlp", "-f", "bv*[height<=720]+ba/b[height<=720]", # 720p ì´í•˜ í™”ì§ˆ ì„ íƒ
            "--download-sections", "*0-10", # 0~10ì´ˆ êµ¬ê°„ë§Œ ë‹¤ìš´ë¡œë“œ
            "-o", temp_path,                # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ì§€ì •
            "--force-overwrite", url        # ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°
        ], check=True, capture_output=True, text=True) # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬, ë¡œê·¸ ìˆ¨ê¹€

        cap = cv2.VideoCapture(temp_path) # ì„ì‹œ ë™ì˜ìƒ íŒŒì¼ ì—´ê¸°
        if not cap.isOpened():
            if os.path.exists(temp_path): os.remove(temp_path)
            return False

        frame_count, max_check, found = 0, 5, False # 5ê°œ í”„ë ˆì„ë§Œ ê²€ì‚¬
        while cap.isOpened() and frame_count < max_check:
            ret, frame = cap.read()
            if not ret: break # í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
            try:
                # í˜„ì¬ í”„ë ˆì„ì—ì„œ target_class(ìë™ì°¨)ë¥¼ íƒì§€
                boxes, _ = run_groundingdino_predict(model=model, image_np=frame, caption=target_class)
                if len(boxes) > 0: # ê°ì²´ê°€ í•˜ë‚˜ë¼ë„ íƒì§€ë˜ë©´
                    print(f"   [ì„±ê³µ] '{target_class}' ê°ì²´ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
                    found = True
                    break # ê²€ì‚¬ ì¤‘ë‹¨
            except Exception as e:
                print(f"   â–¶ï¸ ì˜ˆì¸¡ ì‹¤íŒ¨ í”„ë ˆì„ {frame_count}: {e}")
            frame_count += 1
            
        cap.release() # ë¹„ë””ì˜¤ ê°ì²´ í•´ì œ
        os.remove(temp_path) # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        return found # ê°ì²´ ë°œê²¬ ì—¬ë¶€ ë°˜í™˜

    except Exception: # ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ì˜ˆì¸¡ ê³¼ì •ì—ì„œ ì–´ë–¤ ì˜¤ë¥˜ë¼ë„ ë°œìƒí•˜ë©´
        if os.path.exists(temp_path): os.remove(temp_path) # ì„ì‹œ íŒŒì¼ì´ ë‚¨ì•„ìˆìœ¼ë©´ ì‚­ì œ
        return False # ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ìƒìœ¼ë¡œ ì²˜ë¦¬


# 4. ìœ íš¨ ì˜ìƒ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
def download_valid_videos(video_infos, model, output_dir="./videos"):
    """ê²€ì¦ëœ ì˜ìƒë§Œ ì§€ì •ëœ í´ë”ì— ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    os.makedirs(output_dir, exist_ok=True) # ë‹¤ìš´ë¡œë“œ í´ë” ìƒì„±
    downloaded_count = 0
    for idx, video in enumerate(video_infos):
        print(f"\nâ³ ({idx+1}/{len(video_infos)}) ê²€ì¦ ì‹œë„ ì¤‘: {video['title']}")
        # is_valid_video í•¨ìˆ˜ë¡œ ì˜ìƒì´ ìœ íš¨í•œì§€ í™•ì¸
        if not is_valid_video(video["url"], model=model, target_class="car"):
            print(f"â›” '{'car'}' ì—†ìŒ (ìŠ¤í‚µ): {video['title']}")
            continue # ì—†ìœ¼ë©´ ë‹¤ìŒ ì˜ìƒìœ¼ë¡œ ë„˜ì–´ê°
        
        filename = f"video_{downloaded_count+1}.mp4"
        output_path = os.path.join(output_dir, filename)
        try:
            print(f"â–¶ï¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {video['title']} â†’ {filename}")
            # yt-dlpë¡œ ì „ì²´ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
            subprocess.run(["yt-dlp", "-f", "bv*+ba/b[ext=mp4]/b", "-o", output_path, video["url"]], check=True)
            downloaded_count += 1
        except subprocess.CalledProcessError as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ ë°œìƒ: {video['url']} â†’ {e}")


# 5. ë™ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ í•¨ìˆ˜
def extract_frames_from_videos(video_dir='./videos', frame_root_dir='./frames'):
    """ë‹¤ìš´ë¡œë“œëœ ëª¨ë“  ë™ì˜ìƒì„ 1ì´ˆì— 1í”„ë ˆì„ì”© ì´ë¯¸ì§€ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    os.makedirs(frame_root_dir, exist_ok=True) # í”„ë ˆì„ ì €ì¥ ë£¨íŠ¸ í´ë” ìƒì„±
    video_files = glob.glob(os.path.join(video_dir, '*.mp4'))
    print(f"\në‹¤ìš´ë¡œë“œëœ ë¹„ë””ì˜¤ {len(video_files)}ê°œì— ëŒ€í•´ í”„ë ˆì„ ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    for video_path in video_files:
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        frame_dir = os.path.join(frame_root_dir, video_name)
        os.makedirs(frame_dir, exist_ok=True) # ì˜ìƒë³„ í”„ë ˆì„ ì €ì¥ í´ë” ìƒì„±

        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS) # ë™ì˜ìƒì˜ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜(FPS) í™•ì¸
        frame_interval = int(fps) if fps > 0 else 1 # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì„¤ì • (FPSê°€ 0ì´ë©´ 1í”„ë ˆì„ ê°„ê²©)
        
        frame_idx, saved_idx = 0, 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret: break
            
            # 1ì´ˆ(frame_interval)ë§ˆë‹¤ í•œ ë²ˆì”© í”„ë ˆì„ ì €ì¥
            if frame_idx % frame_interval == 0:
                frame_path = os.path.join(frame_dir, f'frame_{saved_idx:05d}.jpg')
                cv2.imwrite(frame_path, frame)
                saved_idx += 1
            frame_idx += 1
        
        cap.release()
        print(f"ğŸ“¸ {video_name} â†’ {saved_idx}ì¥ í”„ë ˆì„ ì €ì¥ë¨")


# --- ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ---
if __name__ == "__main__":
    # 1. ê²€ìƒ‰í•  í‚¤ì›Œë“œ ì •ì˜
    keywords = ["ì•¼ê°„ ê³ ì†ë„ë¡œ CCTV"]
    
    # 2. ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ ì‹¤í–‰
    video_infos = search_youtube_videos(keywords, limit=5)
    
    if not video_infos:
        print("ê²€ìƒ‰ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        # 3. ìœ íš¨í•œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        download_valid_videos(video_infos, model=model, target_class="car") # target_classë¥¼ ë°”ê¿€ ìˆ˜ ìˆìŒ
        
        # 4. ë‹¤ìš´ë¡œë“œëœ ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ ì‹¤í–‰
        extract_frames_from_videos()
        
        print("\nëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")